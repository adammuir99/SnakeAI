# SnakeAI

## Video Demos 
Explanation Demo (outdated): https://www.youtube.com/watch?v=XULQegvnpDg  
Current High-score: https://www.youtube.com/watch?v=YOtUwOzDOVE

## Strategy
The purpose of this project was to create an AI that would teach itself how to play the popular game Snake (Click [Here](https://github.com/adammuir99/SnakeGame) to see how the game itself was made). Feed-forward neural networks were used as the artifical 'brain' for each snake to determine which direction to move next. For the overall population, a Genetic Algorithm was used to implement evolution and promote genetic diversity.

## Explanation
### Snake
Each snake contains a neural network with a 16-18-18-4 structure.
![Neural Network Topology](https://i.imgur.com/s4NgSEx.png)

(Diagram generated by [this website](https://alexlenail.me/NN-SVG/index.html))

In each cardinal direction (N, E, S, W), the snake stores three values:
* If the first object seen in this direction is food (1.0 or 0.0)
* If the first object seen in this direction is snake (1.0 or 0.0)
* The distance to this object (range from 1.0 to 0.0 where 1.0 is directly adjacent to the snake and 0.0 is on the opposite side of the grid)

If the first two values are 0.0, then neither food or snake body is seen in that direction.The snake will infer that the first object seen must be a wall at a distance determined by the third value. This makes up the first 12 inputs to the neural network. The remaining 4 inputs are binary (1.0 or 0.0) flags that indicate whether the food is above, below, to the left, or right of the snake. The 4 outputs determine the snakes next move: up, down, left, or right.

Each snake tracks its own stats which includes its highscore, whether it finished its game, and the amount of food it has eaten.

Backpropogation is not used to update the weights in the neural networks because after each move we would need to tell the NN what the 'correct' move was. This introduces a problem that is nearly identical to the problem the NN is supposed to solve - determining what the next move should be. Instead we use a Genetic Algorithm to train the data and update the weights, simulating real-life evolution.

### Evolution
The Genetic Algorithm executes the following steps:
1. [A population of randomized snakes are created.](#generation)
2. [All the snakes play the game.](#simulation)
3. [The best snakes are chosen and have their genetics crossed to create a child which will populate the next generation.](#crossover)
4. [The population in the next generation are mutated.](#mutation)
5. Steps 2-4 are repeated.

There are three main values that were adjusted while testing to optimize the evolution process.
* The population size.
* The number of generations to simulate.
* The mutation rate.

The optimal results while testing were achieved with a population size of 50,000 snakes, 200 generations simulated, and a 4% mutation rate.

#### Generation
A number of snakes are created to fill the population. Each snake contains its own neural network acting as its brain. The weights in these neural networks are randomized (random float value between -1.0 and +1.0). The random weights mean most of the snakes will not be smart and will die immediately. A sufficiently large starting population size should be chosen to increase the probability of getting a few snakes that have the 'genes' we are looking for (i.e moving towards the food and avoiding the walls).

#### Simulation
Once the population of snakes is created, we need to determine which snakes have the strongest genes in a 'survival of the fittest' kind of way. Therefore all the snakes must play the game and the snake that achieves the highest score will be deemed the fittest. Their scores increase each time they eat food by a factor relative to the time it took to reach that food. This means a snake that takes 20 moves to reach the food will recieve a higher score than a snake that took 100 moves to reach the food.

#### Crossover
After all the snakes are finished playing the game, the 10 snakes with the highest score are chosen for crossovers. These snakes are ordered by #1 highest score to #10. The crossover process involves creating a new neural network using half of the weights from one network and half of the weights from another network. In this case the #1 snake is crossed with the #2, #3, #4, .. , #10 snakes creating 9 children with new neural networks. The 9 children all play the game to determine which of the children has the highest score. The best child is cloned and fills the entirety of the next generation.

There is no guarantee that taking half of one snakes brain and combining it with half of another snakes brain will create a child that is smarter than either of the parents. This is why we do a crossover on the top 10 snakes and choose the fittest child- to increase the probability of getting a improved neural network from the crossover.

#### Mutation
Since each new generation after the first one is populated entirely by clones of the same snake, they will all play the game the same way and will achieve the same scores. This lack of genetic diversity completely halts evolution and means that each generation will be the exact same as the last, therefore no improvements. To introduce more genetic diversity, we copy nature by implementing random mutations. We go through the weights of each neural network and using the previously defined mutation rate we give a % chance that each weight will be changed to a new, random value.

Choosing a mutation rate that is too low will not create enough genetic diversity in the population. The evolution will stall as there is not a high enough chance for a positively influential mutation to occur.
![0.8% Mutation Rate](https://i.imgur.com/7d0yvxp.png)

But, choosing a mutation rate that is too high will create too much variance and will result in some beneficial genes from previous generations being overwritten by randomized values.
![10% Mutation Rate](https://i.imgur.com/IS62zWl.png)

## Notes
* Increasing the population size greatly improves the results but takes a lot more resources which was the main limiting factor over this project. The highscore was achieved with a population of 50,000 snakes and 200 generations simulated. 50,000 snakes * 200 generations = 10 million neural networks that each have 684 weights. With almost 7 billion weights being used to calculate each move, the training would have taken way too long had I not incorporated multithreading. Instead of simulating the snakes 1 by 1, I used 8-12 threads of my CPU to run the simulations in parallel, greately improving the performance and allowing me to use large population sizes. Luckily, when each snake would play the game it was independent of all the other snakes so the parallel processing was easy to incorporate without having to deal with race conditions or mutexes.
* I had originally used 24 inputs to the neural networks with the same 3 values (first seen is food, first seen is snake, distance to object) but in 8 directions (N, NE, E, SE, S, SW, W, NW). I reduced the inputs to 16 and immediately had better results likely because I reduced a lot of the useless information being input. Adding the 4 inputs that tell the snake the general direction of the food also helped to guide the snake in the right direction.
* For testing purposes each snake had the same set of coordinates that the food would appear in. If the food was randomized then some 'smarter' snakes could get beat by snakes that just had lucky food generation spots. Also keeping the food the same allowed me to replicate the results, so I could repeatedly make the same snake play the game and it would always get the same score.
